{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "239f5568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\asus\\anaconda03\\lib\\site-packages (4.38.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda03\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda03\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda03\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77e5f850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[tflite] in c:\\users\\asus\\anaconda03\\lib\\site-packages (4.38.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda03\\lib\\site-packages (from transformers[tflite]) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from transformers[tflite]) (2022.3.15)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda03\\lib\\site-packages (from transformers[tflite]) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from transformers[tflite]) (1.23.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from transformers[tflite]) (0.21.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from transformers[tflite]) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from transformers[tflite]) (0.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from transformers[tflite]) (23.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from transformers[tflite]) (4.64.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from transformers[tflite]) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[tflite]) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[tflite]) (4.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda03\\lib\\site-packages (from tqdm>=4.27->transformers[tflite]) (0.4.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from requests->transformers[tflite]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from requests->transformers[tflite]) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from requests->transformers[tflite]) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda03\\lib\\site-packages (from requests->transformers[tflite]) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: transformers 4.38.1 does not provide the extra 'tflite'\n"
     ]
    }
   ],
   "source": [
    "pip install transformers[tflite]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28707518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda03\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ASUS\\anaconda03\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ASUS\\anaconda03\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey! I'm Buddy.\n",
      "Feel free to share your thoughts with me.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "class EmotionalSupportAnimalChatbot:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "        self.model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "        self.responses = {\n",
    "            'greeting': [\"Hello! I'm {} your emotional support companion.\", \"Hi there! I'm {}.\", \"Hey! I'm {}.\"],\n",
    "            'comfort': [\"I'm here to provide comfort and support.\", \"You're not alone. I'm here for you.\", \"Feel free to share your thoughts with me.\"],\n",
    "            'encouragement': [\"You're doing great!\", \"Remember, each day is a new opportunity.\", \"I believe in you!\"],\n",
    "            'farewell': [\"Take care! Reach out whenever you need.\", \"Goodbye for now! I'll be here whenever you want to chat.\", \"Remember, I'm just a message away.\"]\n",
    "        }\n",
    "\n",
    "    def generate_response(self, input_text):\n",
    "        input_ids = self.tokenizer.encode(input_text, return_tensors=\"tf\")\n",
    "        output_ids = self.model.generate(input_ids, max_length=100, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95, temperature=0.7)\n",
    "        response = self.tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        return response\n",
    "\n",
    "    def get_response(self, category):\n",
    "        return random.choice(self.responses[category])\n",
    "\n",
    "    def start_conversation(self):\n",
    "        print(self.get_response('greeting').format(self.name))\n",
    "        print(self.get_response('comfort'))\n",
    "\n",
    "    def chat_loop(self):\n",
    "        self.start_conversation()\n",
    "\n",
    "        while True:\n",
    "            user_input = input(\"You: \").lower()\n",
    "\n",
    "            if 'bye' in user_input:\n",
    "                print(self.get_response('farewell'))\n",
    "                break\n",
    "            elif 'encourage' in user_input:\n",
    "                print(self.get_response('encouragement'))\n",
    "            else:\n",
    "                model_input = str(user_input)\n",
    "                model_response = self.generate_response(model_input)\n",
    "                print(f\"Bot: {model_response}\")\n",
    "\n",
    "# Create an instance of the EmotionalSupportAnimalChatbot\n",
    "bot_name = \"Buddy\"\n",
    "esa_bot = EmotionalSupportAnimalChatbot(bot_name)\n",
    "\n",
    "# Start the chat loop\n",
    "esa_bot.chat_loop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ae962f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
